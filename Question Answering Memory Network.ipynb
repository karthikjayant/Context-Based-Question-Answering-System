{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering System using End to End Memory Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.utils.data_utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    if sent is not None:\n",
    "        return [x.strip() for x in re.split('\\W+', sent) if x is not None and x.strip()]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true, only the sentences\n",
    "    that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [word_idx[w] for w in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        y = np.zeros(len(word_idx) + 1)\n",
    "        y[word_idx[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X, maxlen=story_maxlen),\n",
    "            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingVisualizer(keras.callbacks.History):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        pd.DataFrame({key: value for key, value in self.history.items() if key.endswith('loss')}).plot()\n",
    "        axes = pd.DataFrame({key: value for key, value in self.history.items() if key.endswith('acc')}).plot()\n",
    "        axes.set_ylim([0, 1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "tar = tarfile.open(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting train and test stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting stories for the challenge: single_supporting_fact_10k\n"
     ]
    }
   ],
   "source": [
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
    "}\n",
    "challenge_type = 'single_supporting_fact_10k'\n",
    "challenge = challenges[challenge_type]\n",
    "\n",
    "print('Extracting stories for the challenge:', challenge_type)\n",
    "train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "test_stories = get_stories(tar.extractfile(challenge.format('test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_stories), len(test_stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_maxlen, query_maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Vocab size: 20 unique words\n",
      "Story max length: 58 words\n",
      "Query max length: 3 words\n",
      "Number of training stories: 10000\n",
      "Number of test stories: 1000\n",
      "-\n",
      "Here's what a \"story\" tuple looks like (input, query, answer):\n",
      "(['Mary', 'moved', 'to', 'the', 'bathroom', 'John', 'went', 'to', 'the', 'hallway'], ['Where', 'is', 'Mary'], 'bathroom')\n",
      "-\n",
      "Vectorizing the word sequences...\n"
     ]
    }
   ],
   "source": [
    "print('-')\n",
    "print('Vocab size:', vocab_size, 'unique words')\n",
    "print('Story max length:', story_maxlen, 'words')\n",
    "print('Query max length:', query_maxlen, 'words')\n",
    "print('Number of training stories:', len(train_stories))\n",
    "print('Number of test stories:', len(test_stories))\n",
    "print('-')\n",
    "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
    "print(train_stories[0])\n",
    "print('-')\n",
    "print('Vectorizing the word sequences...')\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "idx_word = dict((i+1, c) for i,c in enumerate(vocab))\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n",
    "                                                               word_idx,\n",
    "                                                               story_maxlen,\n",
    "                                                               query_maxlen)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n",
    "                                                            word_idx,\n",
    "                                                            story_maxlen,\n",
    "                                                            query_maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 58), (10000, 3), (10000, 20))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape, queries_train.shape, answers_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "inputs: integer tensor of shape (samples, max_length)\n",
      "inputs_train shape: (10000, 58)\n",
      "inputs_test shape: (1000, 58)\n",
      "-\n",
      "queries: integer tensor of shape (samples, max_length)\n",
      "queries_train shape: (10000, 3)\n",
      "queries_test shape: (1000, 3)\n",
      "-\n",
      "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
      "answers_train shape: (10000, 20)\n",
      "answers_test shape: (1000, 20)\n",
      "-\n",
      "Compiling...\n"
     ]
    }
   ],
   "source": [
    "print('-')\n",
    "print('inputs: integer tensor of shape (samples, max_length)')\n",
    "print('inputs_train shape:', inputs_train.shape)\n",
    "print('inputs_test shape:', inputs_test.shape)\n",
    "print('-')\n",
    "print('queries: integer tensor of shape (samples, max_length)')\n",
    "print('queries_train shape:', queries_train.shape)\n",
    "print('queries_test shape:', queries_test.shape)\n",
    "print('-')\n",
    "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
    "print('answers_train shape:', answers_train.shape)\n",
    "print('answers_test shape:', answers_test.shape)\n",
    "print('-')\n",
    "print('Compiling...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 100\n",
    "batch_size = 32\n",
    "lstm_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: KerasTensor(type_spec=TensorSpec(shape=(None, 58), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
      "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 58, 64), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
      "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 58, 3), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
      "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 3, 64), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n",
      "(None, 58, 3)\n",
      "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 58, 3), dtype=tf.float32, name=None), name='activation/Softmax:0', description=\"created by layer 'activation'\")\n",
      "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 3, 58), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n",
      "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 3, 122), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "input_sequence = Input((story_maxlen,))\n",
    "question = Input((query_maxlen,))\n",
    "\n",
    "print('Input sequence:', input_sequence)\n",
    "print('Question:', question)\n",
    "\n",
    "# encoders\n",
    "# embed the input sequence into a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=query_maxlen))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=query_maxlen))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)\n",
    "\n",
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "print('Input encoded m', input_encoded_m)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "question_encoded = question_encoder(question)\n",
    "print('Question encoded', question_encoded)\n",
    "\n",
    "\n",
    "# compute a 'match' between the first input vector sequence\n",
    "# and the question vector sequence\n",
    "# shape: `(samples, story_maxlen, query_maxlen)\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "print(match.shape)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "print('Response shape', response)\n",
    "\n",
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    "\n",
    "#answer = LSTM(lstm_size, return_sequences=True)(answer)  # Generate tensors of shape 32\n",
    "#answer = Dropout(0.3)(answer)\n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 58)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, None, 64)     1280        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 3, 64)        1280        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 58, 3)        0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 58, 3)        0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 3)      60          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 58, 3)        0           ['activation[0][0]',             \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 3, 58)        0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 122)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           47872       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 20)           1300        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 20)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,792\n",
      "Trainable params: 51,792\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and using Keras Callbacks for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 5s 9ms/step - loss: 1.8936 - accuracy: 0.1643 - val_loss: 1.7872 - val_accuracy: 0.1820\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.7199 - accuracy: 0.2541 - val_loss: 1.5755 - val_accuracy: 0.3490\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.5646 - accuracy: 0.3652 - val_loss: 1.5057 - val_accuracy: 0.3900\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.5078 - accuracy: 0.4045 - val_loss: 1.4284 - val_accuracy: 0.4350\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.4456 - accuracy: 0.4332 - val_loss: 1.3608 - val_accuracy: 0.4700\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.4186 - accuracy: 0.4461 - val_loss: 1.3848 - val_accuracy: 0.4630\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3878 - accuracy: 0.4616 - val_loss: 1.3439 - val_accuracy: 0.4930\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3615 - accuracy: 0.4787 - val_loss: 1.3047 - val_accuracy: 0.5240\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3466 - accuracy: 0.4864 - val_loss: 1.2883 - val_accuracy: 0.5080\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.3203 - accuracy: 0.4922 - val_loss: 1.2857 - val_accuracy: 0.5010\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3077 - accuracy: 0.4991 - val_loss: 1.2945 - val_accuracy: 0.4920\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2875 - accuracy: 0.5014 - val_loss: 1.2546 - val_accuracy: 0.5060\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2762 - accuracy: 0.5065 - val_loss: 1.2250 - val_accuracy: 0.5130\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2681 - accuracy: 0.5083 - val_loss: 1.2155 - val_accuracy: 0.5230\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2546 - accuracy: 0.5135 - val_loss: 1.2306 - val_accuracy: 0.5240\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2447 - accuracy: 0.5135 - val_loss: 1.2314 - val_accuracy: 0.5140\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2309 - accuracy: 0.5151 - val_loss: 1.2236 - val_accuracy: 0.5090\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2253 - accuracy: 0.5194 - val_loss: 1.2130 - val_accuracy: 0.5350\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2079 - accuracy: 0.5228 - val_loss: 1.2031 - val_accuracy: 0.5160\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2044 - accuracy: 0.5237 - val_loss: 1.1969 - val_accuracy: 0.5290\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2015 - accuracy: 0.5193 - val_loss: 1.2185 - val_accuracy: 0.5300\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1892 - accuracy: 0.5261 - val_loss: 1.1788 - val_accuracy: 0.5350\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1880 - accuracy: 0.5288 - val_loss: 1.2074 - val_accuracy: 0.5160\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1783 - accuracy: 0.5235 - val_loss: 1.1883 - val_accuracy: 0.5230\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1749 - accuracy: 0.5231 - val_loss: 1.1857 - val_accuracy: 0.5240\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1675 - accuracy: 0.5273 - val_loss: 1.1757 - val_accuracy: 0.5290\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1612 - accuracy: 0.5299 - val_loss: 1.1803 - val_accuracy: 0.5230\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1613 - accuracy: 0.5217 - val_loss: 1.1741 - val_accuracy: 0.5250\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1569 - accuracy: 0.5357 - val_loss: 1.1760 - val_accuracy: 0.5280\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1409 - accuracy: 0.5392 - val_loss: 1.1726 - val_accuracy: 0.5030\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1381 - accuracy: 0.5299 - val_loss: 1.1633 - val_accuracy: 0.5250\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1279 - accuracy: 0.5368 - val_loss: 1.1596 - val_accuracy: 0.5250\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1287 - accuracy: 0.5383 - val_loss: 1.1684 - val_accuracy: 0.5270\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1088 - accuracy: 0.5508 - val_loss: 1.1764 - val_accuracy: 0.5130\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1039 - accuracy: 0.5500 - val_loss: 1.1507 - val_accuracy: 0.5250\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0650 - accuracy: 0.5796 - val_loss: 1.0965 - val_accuracy: 0.5610\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.9732 - accuracy: 0.6418 - val_loss: 0.9523 - val_accuracy: 0.6690\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.8306 - accuracy: 0.7136 - val_loss: 0.8153 - val_accuracy: 0.7240\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7451 - accuracy: 0.7398 - val_loss: 0.7659 - val_accuracy: 0.7410\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6740 - accuracy: 0.7643 - val_loss: 0.6893 - val_accuracy: 0.7470\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6148 - accuracy: 0.7852 - val_loss: 0.6220 - val_accuracy: 0.7590\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5665 - accuracy: 0.8001 - val_loss: 0.5674 - val_accuracy: 0.7860\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5204 - accuracy: 0.8129 - val_loss: 0.5214 - val_accuracy: 0.8060\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4848 - accuracy: 0.8247 - val_loss: 0.4879 - val_accuracy: 0.8160\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4481 - accuracy: 0.8360 - val_loss: 0.4574 - val_accuracy: 0.8390\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4287 - accuracy: 0.8439 - val_loss: 0.4346 - val_accuracy: 0.8320\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4074 - accuracy: 0.8520 - val_loss: 0.4098 - val_accuracy: 0.8550\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3852 - accuracy: 0.8617 - val_loss: 0.4054 - val_accuracy: 0.8540\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3706 - accuracy: 0.8618 - val_loss: 0.3815 - val_accuracy: 0.8660\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3521 - accuracy: 0.8699 - val_loss: 0.3921 - val_accuracy: 0.8510\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3343 - accuracy: 0.8797 - val_loss: 0.3400 - val_accuracy: 0.8870\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3172 - accuracy: 0.8839 - val_loss: 0.3269 - val_accuracy: 0.8810\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3025 - accuracy: 0.8888 - val_loss: 0.3096 - val_accuracy: 0.8880\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2871 - accuracy: 0.8989 - val_loss: 0.2928 - val_accuracy: 0.8900\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2680 - accuracy: 0.9044 - val_loss: 0.2676 - val_accuracy: 0.9070\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2528 - accuracy: 0.9103 - val_loss: 0.2528 - val_accuracy: 0.9110\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2496 - accuracy: 0.9133 - val_loss: 0.2721 - val_accuracy: 0.9020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2364 - accuracy: 0.9158 - val_loss: 0.2384 - val_accuracy: 0.9170\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2332 - accuracy: 0.9167 - val_loss: 0.2342 - val_accuracy: 0.9240\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2296 - accuracy: 0.9205 - val_loss: 0.2198 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2107 - accuracy: 0.9271 - val_loss: 0.2408 - val_accuracy: 0.9160\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2122 - accuracy: 0.9259 - val_loss: 0.2134 - val_accuracy: 0.9270\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1959 - accuracy: 0.9315 - val_loss: 0.2107 - val_accuracy: 0.9260\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1888 - accuracy: 0.9360 - val_loss: 0.2057 - val_accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1829 - accuracy: 0.9367 - val_loss: 0.2024 - val_accuracy: 0.9390\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1766 - accuracy: 0.9371 - val_loss: 0.2046 - val_accuracy: 0.9340\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1719 - accuracy: 0.9378 - val_loss: 0.1842 - val_accuracy: 0.9420\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1622 - accuracy: 0.9444 - val_loss: 0.1809 - val_accuracy: 0.9410\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1621 - accuracy: 0.9428 - val_loss: 0.1933 - val_accuracy: 0.9380\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1559 - accuracy: 0.9446 - val_loss: 0.1759 - val_accuracy: 0.9360\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1553 - accuracy: 0.9465 - val_loss: 0.1904 - val_accuracy: 0.9340\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1476 - accuracy: 0.9502 - val_loss: 0.1609 - val_accuracy: 0.9470\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1414 - accuracy: 0.9504 - val_loss: 0.1578 - val_accuracy: 0.9450\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1326 - accuracy: 0.9541 - val_loss: 0.1616 - val_accuracy: 0.9420\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1356 - accuracy: 0.9544 - val_loss: 0.1722 - val_accuracy: 0.9420\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1313 - accuracy: 0.9541 - val_loss: 0.1660 - val_accuracy: 0.9470\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1286 - accuracy: 0.9562 - val_loss: 0.1587 - val_accuracy: 0.9510\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1176 - accuracy: 0.9590 - val_loss: 0.1705 - val_accuracy: 0.9460\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1165 - accuracy: 0.9584 - val_loss: 0.1534 - val_accuracy: 0.9510\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1117 - accuracy: 0.9602 - val_loss: 0.1503 - val_accuracy: 0.9540\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1032 - accuracy: 0.9632 - val_loss: 0.1550 - val_accuracy: 0.9520\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1058 - accuracy: 0.9632 - val_loss: 0.1398 - val_accuracy: 0.9520\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1023 - accuracy: 0.9629 - val_loss: 0.1237 - val_accuracy: 0.9580\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0897 - accuracy: 0.9681 - val_loss: 0.1375 - val_accuracy: 0.9550\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0963 - accuracy: 0.9652 - val_loss: 0.1430 - val_accuracy: 0.9570\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0855 - accuracy: 0.9694 - val_loss: 0.1348 - val_accuracy: 0.9600\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0873 - accuracy: 0.9701 - val_loss: 0.1340 - val_accuracy: 0.9610\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0855 - accuracy: 0.9721 - val_loss: 0.1402 - val_accuracy: 0.9490\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0795 - accuracy: 0.9724 - val_loss: 0.1292 - val_accuracy: 0.9620\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0790 - accuracy: 0.9732 - val_loss: 0.1137 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0729 - accuracy: 0.9754 - val_loss: 0.1212 - val_accuracy: 0.9610\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0734 - accuracy: 0.9727 - val_loss: 0.1500 - val_accuracy: 0.9530\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0712 - accuracy: 0.9738 - val_loss: 0.1173 - val_accuracy: 0.9670\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0738 - accuracy: 0.9758 - val_loss: 0.1214 - val_accuracy: 0.9670\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0637 - accuracy: 0.9781 - val_loss: 0.1328 - val_accuracy: 0.9590\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0686 - accuracy: 0.9773 - val_loss: 0.1118 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0621 - accuracy: 0.9800 - val_loss: 0.1224 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0631 - accuracy: 0.9779 - val_loss: 0.1245 - val_accuracy: 0.9620\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0594 - accuracy: 0.9804 - val_loss: 0.1043 - val_accuracy: 0.9700\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.1355 - val_accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "model.fit([inputs_train, queries_train], answers_train, batch_size, train_epochs,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "John travelled to the hallway Mary journeyed to the bathroom Where is John | Prediction: hallway | Ground Truth: hallway\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "John travelled to the hallway Mary journeyed to the bathroom Daniel went back to the bathroom John moved to the bedroom Where is Mary | Prediction: bathroom | Ground Truth: bathroom\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "John travelled to the hallway Mary journeyed to the bathroom Daniel went back to the bathroom John moved to the bedroom John went to the hallway Sandra journeyed to the kitchen Where is Sandra | Prediction: kitchen | Ground Truth: kitchen\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "John travelled to the hallway Mary journeyed to the bathroom Daniel went back to the bathroom John moved to the bedroom John went to the hallway Sandra journeyed to the kitchen Sandra travelled to the hallway John went to the garden Where is Sandra | Prediction: hallway | Ground Truth: hallway\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "John travelled to the hallway Mary journeyed to the bathroom Daniel went back to the bathroom John moved to the bedroom John went to the hallway Sandra journeyed to the kitchen Sandra travelled to the hallway John went to the garden Sandra went back to the bathroom Sandra moved to the kitchen Where is Sandra | Prediction: kitchen | Ground Truth: kitchen\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Sandra travelled to the kitchen Sandra travelled to the hallway Where is Sandra | Prediction: hallway | Ground Truth: hallway\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Sandra travelled to the kitchen Sandra travelled to the hallway Mary went to the bathroom Sandra moved to the garden Where is Sandra | Prediction: garden | Ground Truth: garden\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Sandra travelled to the kitchen Sandra travelled to the hallway Mary went to the bathroom Sandra moved to the garden Sandra travelled to the office Daniel journeyed to the hallway Where is Daniel | Prediction: hallway | Ground Truth: hallway\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Sandra travelled to the kitchen Sandra travelled to the hallway Mary went to the bathroom Sandra moved to the garden Sandra travelled to the office Daniel journeyed to the hallway Daniel journeyed to the office John moved to the hallway Where is Sandra | Prediction: office | Ground Truth: office\n",
      "-----------------------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Sandra travelled to the kitchen Sandra travelled to the hallway Mary went to the bathroom Sandra moved to the garden Sandra travelled to the office Daniel journeyed to the hallway Daniel journeyed to the office John moved to the hallway John travelled to the bathroom John journeyed to the office Where is Daniel | Prediction: office | Ground Truth: office\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "        current_inp = test_stories[i]\n",
    "        current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
    "        current_prediction = model.predict([current_story, current_query])\n",
    "        current_prediction = idx_word[np.argmax(current_prediction)]\n",
    "        print(' '.join(current_inp[0]), ' '.join(current_inp[1]), '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
    "        print(\"-----------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
